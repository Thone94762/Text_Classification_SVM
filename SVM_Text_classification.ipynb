{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>word4</th>\n",
       "      <th>word5</th>\n",
       "      <th>word6</th>\n",
       "      <th>word7</th>\n",
       "      <th>word8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>computational</td>\n",
       "      <td>unsupervise</td>\n",
       "      <td>supervised</td>\n",
       "      <td>data</td>\n",
       "      <td>mining</td>\n",
       "      <td>scientists</td>\n",
       "      <td>prediction</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>computational</td>\n",
       "      <td>unsupervise</td>\n",
       "      <td>supervised</td>\n",
       "      <td>data</td>\n",
       "      <td>mining</td>\n",
       "      <td>scientists</td>\n",
       "      <td>prediction</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>analystics</td>\n",
       "      <td>automates</td>\n",
       "      <td>human</td>\n",
       "      <td>make</td>\n",
       "      <td>decision</td>\n",
       "      <td>minimal</td>\n",
       "      <td>intervention</td>\n",
       "      <td>analystic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>branch</td>\n",
       "      <td>idea</td>\n",
       "      <td>identify</td>\n",
       "      <td>pattern</td>\n",
       "      <td>decision</td>\n",
       "      <td>make</td>\n",
       "      <td>analytical</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>branch</td>\n",
       "      <td>idea</td>\n",
       "      <td>identify</td>\n",
       "      <td>pattern</td>\n",
       "      <td>decision</td>\n",
       "      <td>make</td>\n",
       "      <td>analytical</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>large</td>\n",
       "      <td>extremely</td>\n",
       "      <td>data</td>\n",
       "      <td>sets</td>\n",
       "      <td>voluminous</td>\n",
       "      <td>complex</td>\n",
       "      <td>data</td>\n",
       "      <td>storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>large</td>\n",
       "      <td>extremely</td>\n",
       "      <td>data</td>\n",
       "      <td>sets</td>\n",
       "      <td>voluminous</td>\n",
       "      <td>complex</td>\n",
       "      <td>data</td>\n",
       "      <td>storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>business</td>\n",
       "      <td>informatics</td>\n",
       "      <td>big</td>\n",
       "      <td>data</td>\n",
       "      <td>grow</td>\n",
       "      <td>rapidly</td>\n",
       "      <td>diverse</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>business</td>\n",
       "      <td>informatics</td>\n",
       "      <td>big</td>\n",
       "      <td>data</td>\n",
       "      <td>grow</td>\n",
       "      <td>rapidly</td>\n",
       "      <td>diverse</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>business</td>\n",
       "      <td>informatics</td>\n",
       "      <td>big</td>\n",
       "      <td>data</td>\n",
       "      <td>grow</td>\n",
       "      <td>rapidly</td>\n",
       "      <td>diverse</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Type          word1        word2       word3        word4  \\\n",
       "0   machine learning          field    Computer      Science  statistical   \n",
       "1   machine learning  computational  unsupervise  supervised         data   \n",
       "2   machine learning  computational  unsupervise  supervised         data   \n",
       "3   machine learning          field    Computer      Science  statistical   \n",
       "4   machine learning          field    Computer      Science  statistical   \n",
       "5   machine learning          field    Computer      Science  statistical   \n",
       "6   machine learning          field    Computer      Science  statistical   \n",
       "7   machine learning     analystics    automates       human         make   \n",
       "8   machine learning         branch         idea    identify      pattern   \n",
       "9   machine learning         branch         idea    identify      pattern   \n",
       "10          Big Data          large    extremely        data         sets   \n",
       "11          Big Data          large    extremely        data         sets   \n",
       "12          Big Data        variety     velocity      volume      capture   \n",
       "13          Big Data       business  informatics         big         data   \n",
       "14          Big Data       business  informatics         big         data   \n",
       "15          Big Data       business  informatics         big         data   \n",
       "16          Big Data        variety     velocity      volume      capture   \n",
       "17          Big Data        variety     velocity      volume      capture   \n",
       "18          Big Data        variety     velocity      volume      capture   \n",
       "19          Big Data        variety     velocity      volume      capture   \n",
       "\n",
       "         word5       word6          word7      word8  \n",
       "0   techniques     pattern    recognition  filtering  \n",
       "1       mining  scientists     prediction      learn  \n",
       "2       mining  scientists     prediction      learn  \n",
       "3   techniques     pattern    recognition  filtering  \n",
       "4   techniques     pattern    recognition  filtering  \n",
       "5   techniques     pattern    recognition  filtering  \n",
       "6   techniques     pattern    recognition  filtering  \n",
       "7     decision     minimal   intervention  analystic  \n",
       "8     decision        make     analytical      model  \n",
       "9     decision        make     analytical      model  \n",
       "10  voluminous     complex           data    storage  \n",
       "11  voluminous     complex           data    storage  \n",
       "12     sharing    transfer  visualization   analysis  \n",
       "13        grow     rapidly        diverse        big  \n",
       "14        grow     rapidly        diverse        big  \n",
       "15        grow     rapidly        diverse        big  \n",
       "16     sharing    transfer  visualization   analysis  \n",
       "17     sharing    transfer  visualization   analysis  \n",
       "18     sharing    transfer  visualization   analysis  \n",
       "19     sharing    transfer  visualization   analysis  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=pd.read_csv('textclass.csv')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>computational</td>\n",
       "      <td>unsupervise</td>\n",
       "      <td>supervised</td>\n",
       "      <td>data</td>\n",
       "      <td>mining</td>\n",
       "      <td>scientists</td>\n",
       "      <td>prediction</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>computational</td>\n",
       "      <td>unsupervise</td>\n",
       "      <td>supervised</td>\n",
       "      <td>data</td>\n",
       "      <td>mining</td>\n",
       "      <td>scientists</td>\n",
       "      <td>prediction</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>field</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Science</td>\n",
       "      <td>statistical</td>\n",
       "      <td>techniques</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>filtering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>analystics</td>\n",
       "      <td>automates</td>\n",
       "      <td>human</td>\n",
       "      <td>make</td>\n",
       "      <td>decision</td>\n",
       "      <td>minimal</td>\n",
       "      <td>intervention</td>\n",
       "      <td>analystic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>branch</td>\n",
       "      <td>idea</td>\n",
       "      <td>identify</td>\n",
       "      <td>pattern</td>\n",
       "      <td>decision</td>\n",
       "      <td>make</td>\n",
       "      <td>analytical</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>branch</td>\n",
       "      <td>idea</td>\n",
       "      <td>identify</td>\n",
       "      <td>pattern</td>\n",
       "      <td>decision</td>\n",
       "      <td>make</td>\n",
       "      <td>analytical</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>large</td>\n",
       "      <td>extremely</td>\n",
       "      <td>data</td>\n",
       "      <td>sets</td>\n",
       "      <td>voluminous</td>\n",
       "      <td>complex</td>\n",
       "      <td>data</td>\n",
       "      <td>storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>large</td>\n",
       "      <td>extremely</td>\n",
       "      <td>data</td>\n",
       "      <td>sets</td>\n",
       "      <td>voluminous</td>\n",
       "      <td>complex</td>\n",
       "      <td>data</td>\n",
       "      <td>storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>business</td>\n",
       "      <td>informatics</td>\n",
       "      <td>big</td>\n",
       "      <td>data</td>\n",
       "      <td>grow</td>\n",
       "      <td>rapidly</td>\n",
       "      <td>diverse</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>business</td>\n",
       "      <td>informatics</td>\n",
       "      <td>big</td>\n",
       "      <td>data</td>\n",
       "      <td>grow</td>\n",
       "      <td>rapidly</td>\n",
       "      <td>diverse</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>business</td>\n",
       "      <td>informatics</td>\n",
       "      <td>big</td>\n",
       "      <td>data</td>\n",
       "      <td>grow</td>\n",
       "      <td>rapidly</td>\n",
       "      <td>diverse</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>variety</td>\n",
       "      <td>velocity</td>\n",
       "      <td>volume</td>\n",
       "      <td>capture</td>\n",
       "      <td>sharing</td>\n",
       "      <td>transfer</td>\n",
       "      <td>visualization</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0              1            2           3            4  \\\n",
       "0   machine learning          field    Computer      Science  statistical   \n",
       "1   machine learning  computational  unsupervise  supervised         data   \n",
       "2   machine learning  computational  unsupervise  supervised         data   \n",
       "3   machine learning          field    Computer      Science  statistical   \n",
       "4   machine learning          field    Computer      Science  statistical   \n",
       "5   machine learning          field    Computer      Science  statistical   \n",
       "6   machine learning          field    Computer      Science  statistical   \n",
       "7   machine learning     analystics    automates       human         make   \n",
       "8   machine learning         branch         idea    identify      pattern   \n",
       "9   machine learning         branch         idea    identify      pattern   \n",
       "10          Big Data          large    extremely        data         sets   \n",
       "11          Big Data          large    extremely        data         sets   \n",
       "12          Big Data        variety     velocity      volume      capture   \n",
       "13          Big Data       business  informatics         big         data   \n",
       "14          Big Data       business  informatics         big         data   \n",
       "15          Big Data       business  informatics         big         data   \n",
       "16          Big Data        variety     velocity      volume      capture   \n",
       "17          Big Data        variety     velocity      volume      capture   \n",
       "18          Big Data        variety     velocity      volume      capture   \n",
       "19          Big Data        variety     velocity      volume      capture   \n",
       "\n",
       "             5           6              7          8  \n",
       "0   techniques     pattern    recognition  filtering  \n",
       "1       mining  scientists     prediction      learn  \n",
       "2       mining  scientists     prediction      learn  \n",
       "3   techniques     pattern    recognition  filtering  \n",
       "4   techniques     pattern    recognition  filtering  \n",
       "5   techniques     pattern    recognition  filtering  \n",
       "6   techniques     pattern    recognition  filtering  \n",
       "7     decision     minimal   intervention  analystic  \n",
       "8     decision        make     analytical      model  \n",
       "9     decision        make     analytical      model  \n",
       "10  voluminous     complex           data    storage  \n",
       "11  voluminous     complex           data    storage  \n",
       "12     sharing    transfer  visualization   analysis  \n",
       "13        grow     rapidly        diverse        big  \n",
       "14        grow     rapidly        diverse        big  \n",
       "15        grow     rapidly        diverse        big  \n",
       "16     sharing    transfer  visualization   analysis  \n",
       "17     sharing    transfer  visualization   analysis  \n",
       "18     sharing    transfer  visualization   analysis  \n",
       "19     sharing    transfer  visualization   analysis  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hearder removing\n",
    "text=pd.read_csv('textclass.csv',header=None)\n",
    "\n",
    "text=pd.read_csv('textclass.csv',header=None,usecols=range(0,9),skiprows=1)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['field', 'Computer ', 'Science', 'statistical', 'techniques',\n",
       "        'pattern', 'recognition', 'filtering'],\n",
       "       ['computational', 'unsupervise', 'supervised', 'data', 'mining',\n",
       "        'scientists', 'prediction', 'learn'],\n",
       "       ['computational', 'unsupervise', 'supervised', 'data', 'mining',\n",
       "        'scientists', 'prediction', 'learn'],\n",
       "       ['field', 'Computer ', 'Science', 'statistical', 'techniques',\n",
       "        'pattern', 'recognition', 'filtering'],\n",
       "       ['field', 'Computer ', 'Science', 'statistical', 'techniques',\n",
       "        'pattern', 'recognition', 'filtering'],\n",
       "       ['field', 'Computer ', 'Science', 'statistical', 'techniques',\n",
       "        'pattern', 'recognition', 'filtering'],\n",
       "       ['field', 'Computer ', 'Science', 'statistical', 'techniques',\n",
       "        'pattern', 'recognition', 'filtering'],\n",
       "       ['analystics', 'automates', 'human', 'make', 'decision',\n",
       "        'minimal', 'intervention', 'analystic'],\n",
       "       ['branch', 'idea', 'identify', 'pattern', 'decision', 'make',\n",
       "        'analytical', 'model'],\n",
       "       ['branch', 'idea', 'identify', 'pattern', 'decision', 'make',\n",
       "        'analytical', 'model'],\n",
       "       ['large', 'extremely', 'data', 'sets', 'voluminous', 'complex',\n",
       "        'data', 'storage'],\n",
       "       ['large', 'extremely', 'data', 'sets', 'voluminous', 'complex',\n",
       "        'data', 'storage'],\n",
       "       ['variety', 'velocity', 'volume', 'capture', 'sharing',\n",
       "        'transfer', 'visualization', 'analysis'],\n",
       "       ['business', 'informatics', 'big', 'data', 'grow', 'rapidly',\n",
       "        'diverse', 'big'],\n",
       "       ['business', 'informatics', 'big', 'data', 'grow', 'rapidly',\n",
       "        'diverse', 'big'],\n",
       "       ['business', 'informatics', 'big', 'data', 'grow', 'rapidly',\n",
       "        'diverse', 'big'],\n",
       "       ['variety', 'velocity', 'volume', 'capture', 'sharing',\n",
       "        'transfer', 'visualization', 'analysis'],\n",
       "       ['variety', 'velocity', 'volume', 'capture', 'sharing',\n",
       "        'transfer', 'visualization', 'analysis'],\n",
       "       ['variety', 'velocity', 'volume', 'capture', 'sharing',\n",
       "        'transfer', 'visualization', 'analysis'],\n",
       "       ['variety', 'velocity', 'volume', 'capture', 'sharing',\n",
       "        'transfer', 'visualization', 'analysis']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert array\n",
    "x=pd.read_csv('textclass.csv',header=None,usecols=range(1,9),skiprows=1)\n",
    "x=np.array(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['machine learning'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data'],\n",
       "       ['Big Data']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert array (textclass)\n",
    "y=pd.read_csv('textclass.csv',header=None,usecols=range(0,1),skiprows=1)\n",
    "y=np.array(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\tt\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\tt\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding\n",
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y=le.transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 0, 5, 4, 3, 5, 3],\n",
       "       [3, 5, 5, 1, 2, 5, 4, 4],\n",
       "       [3, 5, 5, 1, 2, 5, 4, 4],\n",
       "       [4, 0, 0, 5, 4, 3, 5, 3],\n",
       "       [4, 0, 0, 5, 4, 3, 5, 3],\n",
       "       [4, 0, 0, 5, 4, 3, 5, 3],\n",
       "       [4, 0, 0, 5, 4, 3, 5, 3],\n",
       "       [0, 1, 3, 2, 0, 2, 3, 1],\n",
       "       [1, 3, 4, 3, 0, 1, 0, 5],\n",
       "       [1, 3, 4, 3, 0, 1, 0, 5],\n",
       "       [5, 2, 2, 4, 5, 0, 1, 6],\n",
       "       [5, 2, 2, 4, 5, 0, 1, 6],\n",
       "       [6, 6, 6, 0, 3, 6, 6, 0],\n",
       "       [2, 4, 1, 1, 1, 4, 2, 2],\n",
       "       [2, 4, 1, 1, 1, 4, 2, 2],\n",
       "       [2, 4, 1, 1, 1, 4, 2, 2],\n",
       "       [6, 6, 6, 0, 3, 6, 6, 0],\n",
       "       [6, 6, 6, 0, 3, 6, 6, 0],\n",
       "       [6, 6, 6, 0, 3, 6, 6, 0],\n",
       "       [6, 6, 6, 0, 3, 6, 6, 0]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding all features with loop\n",
    "from sklearn import preprocessing\n",
    "for j in range(0,8):\n",
    "    le.fit(x[:,j])\n",
    "    x[:,j]=le.transform(x[:,j])\n",
    "#fe=preprocessing.LabelEncoder()\n",
    "#fe.fit(x)\n",
    "#x=fe.transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8) (4, 8) (16,) (4,)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=12)\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\tt\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "clf=SVC(kernel=\"poly\")              #'linear' , 'rbf' , 'poly' , 'sigmoid'\n",
    "clf.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 6, 7, 4, 5, 3], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input text encode\n",
    "test=[\"field\",\"Computer\",\"Science\",\"statistical\",\"techniques\",\"pattern\",\"recognition\",\"filtering\"]\n",
    "le=preprocessing.LabelEncoder()\n",
    "le.fit(test)\n",
    "test=le.transform(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2. 0. 1. 6. 7. 4. 5. 3.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-90f376250d6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input Text is machine Learning\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tt\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \"\"\"\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tt\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \"\"\"\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tt\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n\u001b[1;32m--> 454\u001b[1;33m                         accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    455\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tt\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2. 0. 1. 6. 7. 4. 5. 3.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "t=clf.predict(test)\n",
    "print(t)\n",
    "if(t==1):\n",
    "    print(\"Input Text is machine Learning\")\n",
    "if(t==0):\n",
    "    print(\"Input Text is Big data\")\n",
    "tt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#Testing with input data\n",
    "test=[4, 0, 0, 5, 4, 3, 5, 3]\n",
    "test=np.array(test)\n",
    "tt=test.reshape(1,-1)\n",
    "\n",
    "t=clf.predict(tt)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 6, 7, 4, 5, 3], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input text encode\n",
    "test=[\"field\",\"Computer\",\"Science\",\"statistical\",\"techniques\",\"pattern\",\"recognition\",\"filtering\"]\n",
    "le=preprocessing.LabelEncoder()\n",
    "le.fit(test)\n",
    "test=le.transform(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Input Text is machine Learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1, 6, 7, 4, 5, 3]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing with input data\n",
    "\n",
    "test=np.array(test)\n",
    "tt=test.reshape(1,-1)\n",
    "\n",
    "t=clf.predict(tt)\n",
    "print(t)\n",
    "if(t==1):\n",
    "    print(\"Input Text is machine Learning\")\n",
    "if(t==0):\n",
    "    print(\"Input Text is Big data\")\n",
    "tt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text[2, 0, 1, 6, 7, 4, 5, 3]\n",
      "[1]\n",
      "Input Text is machine Learning\n"
     ]
    }
   ],
   "source": [
    "inputtext=input(\"Enter Text\")\n",
    "inputarr=inputtext.split(' ')\n",
    "#encode\n",
    "le=preprocessing.LabelEncoder()\n",
    "le.fit(inputarr)\n",
    "test=le.transform(inputarr)\n",
    "test\n",
    "#predict\n",
    "test=np.array(test)\n",
    "tt=test.reshape(1,-1)\n",
    "\n",
    "t=clf.predict(tt)\n",
    "print(t)\n",
    "if(t==1):\n",
    "    print(\"Input Text is machine Learning\")\n",
    "if(t==0):\n",
    "    print(\"Input Text is Big data\")\n",
    "#else: print(\"wrong\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
